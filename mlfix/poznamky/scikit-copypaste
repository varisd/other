import os, sys, argparse
import gzip
import model
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import RidgeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import Perceptron
from sklearn.feature_extraction import DictVectorizer
from sklearn.feature_extraction import FeatureHasher
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import TruncatedSVD
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn.pipeline import Pipeline, FeatureUnion
from sklearn import tree
from sklearn.externals import joblib

features_ignore_regex = ["tag","lemma","form", "node_id"]
features_ignore = [ "old_node_id", "wrong_form_1", "wrong_form_2" ]

def ignored_field (feature_name):
    features_ignore_regex = [ "lemma", "form", "tag" ]
    ignored = False;
    for regex in features_ignore_regex:
        if regex in feature_name:
            ignored = True
    return ignored

def transform_features(features):
        """ Transform features with string values into new sets of features. """
        transformed = dict()
        if isinstance(features, unicode):
            raise ValueError(features)
        for name, value in features.iteritems():
            if isinstance(value, basestring):
                name = "%s_%s" % (name,value)
                value = 1.
            transformed[name] = float(value)
        return transformed

def count_features (feature_names):
    filtered_names = list(set(feature_names) - set(features_ignore))
    for regex in features_ignore_regex:
        filtered_names = filter(lambda x: not regex in x, filtered_names)
    return len(filtered_names)

def ignored_field (feature_name):
    ignored = False;
    for regex in features_ignore_regex:
        if regex in feature_name:
            ignored = True
    return ignored

def line2dict (feat_names, feat_vals, ignore_blank):
    """ Create dictionary from the input line."""
    result = dict()
    if len(feat_names) != len(feat_vals):
        raise ValueError("Feature vector length does not match: expected=" + len(feat_names) + " got=" + len(feat_vals))
    for i in range(len(feat_names)):
        if ignore_blank and feat_vals[i] == "":
            continue
        result[feat_names[i]] = feat_vals[i]
    return result

def split_targets_feats (input_dict, targets):
    target_dict = dict()
    feat_dict = dict()
    for key,item in input_dict.iteritems():
        if key in targets:
            target_dict[key] = item
        elif ignored_field(key) != True:
            feat_dict[key] = item
    return target_dict, feat_dict

def line2base (targets, values):
    result = dict()
    if len(targets) != len(values):
        raise ValueError("Number of targets between baseline and predicted does not match: expected=" + len(targets) + " got=" + len(values))
    for i in range(len(targets)):
        result[targets[i]] = values[i]
    return result


fh = gzip.open("../test.gz", 'rb', 'UTF-8')
line = fh.readline().rstrip("\n")
feature_names =  line.split("\t")
targets = ["wrong_form_2"]

registered_feat_names = dict()
multiclass = False
if len(targets) > 1:
     multiclass = True

# Prepare the data
data_X = []
data_Y = []
while True:
    line = fh.readline().rstrip("\n")
    if not line:
        break
    feat_values = line.split("\t")
    line_dict = line2dict(feature_names, feat_values, False)
    tdict, fdict = split_targets_feats(line_dict, targets)
    for key,item in fdict.iteritems():
        registered_feat_names[key] = 1
    data_X.append(fdict)
    data_Y.append(tdict)

fh.close()

vectorizer = DictVectorizer(sparse=True)
encoder = LabelEncoder()
scaler = StandardScaler(with_mean=False)

sys.stderr.write("# of initial features: %d\n" % (len(registered_feat_names)))

#pred = data_Y

#Xtr = scaler.fit_transform(vectorizer.fit_transform(data_X))
Xtr = vectorizer.fit_transform(data_X)
Ytr = encoder.fit_transform(data_Y)













### OLD ###

fh = gzip.open("../2016-04-20_15-05-19_2211904814_autodesk_train_refparents_collect/all_edits.tsv.gz", 'rb', 'UTF-8')
line = fh.readline().rstrip("\n")
feature_names =  line.split("\t")
targets = ["wrong_form_2"] 
model_type = "knn"
feat_ratio=1.0

train_X = []
train_Y = []
while True:
    line = fh.readline().rstrip("\n")
    if not line:
        break
    feat_values = line.split("\t")
    feat_row = dict()
    target_row = dict()
    for i in range(len(feature_names)):
        # Collect target values for the other classifiers
        if feature_names[i] in targets:
            target_row.update({feature_names[i]:feat_values[i]})
        elif "new" not in feature_names[i] and not feature_names[i] in features_ignore and not ignored_field(feature_names[i]) and feat_values[i] != "":
            feat_row.update({feature_names[i]:feat_values[i]})
    train_X.append(feat_row)
    train_Y.append(target_row)

Xtr = [transform_features(i) for i in train_X]

n_features = int(feat_ratio * count_features(feature_names))
if n_features > len(feature_names):
    raise ValueError(n_features)


model = KNeighborsClassifier()
label_encoder = LabelEncoder()
feat_vectorizer = FeatureHasher(non_negative=True)
selector = SelectKBest(chi2, k=n_features)
combined_features = FeatureUnion(['selectKBest', selector])
#pipeline = Pipeline([('vectorizer', feat_vectorizer), ('features', combined_features), ('model', model)])
pipeline = Pipeline([('vectorizer', feat_vectorizer)])

Ytr = label_encoder.fit_transform(train_Y)
