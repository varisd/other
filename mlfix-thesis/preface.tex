\chapter{Introduction}
%\chapter*{Introduction}
%\addcontentsline{toc}{chapter}{Introduction}

In this thesis, we present a statistical post-editing tool MLFix
based on its rule-based predecessor Depfix \citep{depfix:2014}.
We aim to use statistical machine learning methods to generalize a subset of Depfix rules
and create a fairly language-independent automatic post-editing (APE) tool.
Our main goal is to find a reasonable trade-off between the amount
of linguistic knowledge needed in the training and input data
%gathered from the input data
and the dependence
on language-specific third-party analysis tools.
We also want to specify the
machine learning (ML) task which our APE component should accomplish and train
a sufficient ML model for correcting machine translation (MT) output.
The system was developed using English-Czech language pair, however, we also present
a preliminary results we gathered from English-German language pair experiments.

\section{Task Motivation}

Even though the state-of-the-art MT systems have been gradually improving in the
past few decades, they are still not perfect. Currently, the most popular statistical machine
translation (SMT) systems can be fairly effective even 
with little or no
%without any or a little initial
linguistic knowledge about the concerned language pair given they have access to sufficient
amount of parallel data. However, when translating into morphologically rich languages,
data sparsity increases rapidly and such systems quickly begin to introduce grammatical
errors into the translated sentences and worsen the overall fluency of the translation.

Still, these systems can be of help to the human translators since it is usually less costly
to start with a partially incorrect translations provided by the SMT system and have
a human translator correct them than to translate the source text manually.
Human post-editors can however still be quite expensive so naturally, there have been
attempts to automate this process with automatic post-editing tools.

\section{Related Work}

Up to this date, there have been various approaches to the task of automatic
error correction of machine translation output, each with a different level of success.

The very first attempts in the field of automatic post-editing \citep{simard2007rule}
focused on applying phrase-based statistical machine translation (PB-SMT)
system on the output of rule-base machine translation. The system was trained on monolingual
bitextual data containing the MT output as the source sentence and the reference translation as
the target sentence. This phrase-based automatic post-editor (PB-APE) helped to significantly improve
the performance of the rule-based MT system in question.
There were also attempts to apply the post-editing component
on a phrase-based translation system but the combined system performed slightly worse in comparison
with the standalone SMT system.

Further experiments with PB-SMT $+$ PB-APE \citep{bechara:2011} were done
on English-French and French-English translation, where significant improvements were reported
for the latter translation direction. They improved the design suggested by Simard et al. by
creating a purely statistical pipeline. The PB-APE was then expanded by adding further 
context information about the source sentence to the SMT-generated output (used as an input for
the PB-APE) reporting further improvement in performance.

These previous attempts can be considered purely statistical since only a little amount of linguistic
knowledge about the concerned languages was used during development. To gain further insight into
the task of automatic post-editing, a more thorough analysis of the most frequent errors made by the current
SMT systems was performed by \citet{bechara:master} and later by \citet{biblio:RoAutomaticpostediting2013}, the former
for English-French and the latter for English-Czech.

The error analysis was later used during development of the rule-based APE Depfix \citep{depfix:2014},
which was designed to correct errors made by the English-Czech SMT systems.
The system uses a set of finely hand-crafted rules that aim at identifying
and correcting morphological errors such as incorrect agreement or valency, which are
often encountered during English-Czech machine translation. It does not focus on a lexical errors
although some minor corrections, e.g. insertion of missing reflexive particles, are made. The system
succeeded to improve output of various MT systems and was deployed as a stable part of the
Chimera \citep{bojar-rosa-tamchyna:2013:WMT} MT system.

The idea behind Depfix system seems promising, however, due to its rule-based nature, it is difficult
to apply the APE on a different language pair since it would require costly modifications to the
existing set of rules. One of the goals of this thesis is to try to replace the rule-based blocks
by statistical ones so they can be applied to 
%the different target language
MT output in a new target language more easily, simply
by training an appropriate statistical model.

%"Better Evaluation for Grammatical Error Correction" Dahlmeier
% napsat az do model tuningu ???
% Correction model for non-MT generated errors (classification)
% Important -> balancing training data

\section{Thesis Structure}
%strucny popis depfixu? popis castych chyb ???

%odkazy
In~Chapter~\ref{chap:system_descr}, we describe MLFix data processing
pipeline and introduce all the tools we use.
In~Chapter~\ref{chap:data}, we take a look at all datasets which we used during our system
development and analyze their usefulness for our system.
In~Chapter~\ref{chap:task_descr}, we define the post-editing task, go through
various modifications of the task we considered and explain our
approach with the support of our analysis of the available data.
In~Chapter~\ref{chap:tuning}, we describe the process of the development
of the statistical models for the MLFix post-editing component and present
results of the evaluation of the trained models.
In~Chapter~\ref{chap:eval}, we evaluate the performance of the whole MLFix system
and analyze the level of contribution to the resulting performance
of each individual statistical component.
In~Chapter~\ref{chap:german}, we briefly describe our modifications to English-Czech pipeline
when used on English-German language pair, then summarize the differences
in the training data and model training between the two language pairs. The chapter concludes with an evaluation of the English-German pipeline.
%In chapter 8, we present performance results of the modified English-German
%pipeline.
We conclude the thesis in Chapter~\ref{chap:conclusion}.

We include a summary of the contents of the attached CD in Attachment~\ref{attach:cd} and a full English-Czech and English-German Treex scenario in Attachment~\ref{attach:scen}.

