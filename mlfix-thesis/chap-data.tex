\chapter{Available data}
\label{chap:data}

% dostupna data
% mnozstvi
% popis
% vyuziti

%XXX TOTO ZREJME AZ DO POPISU SYSTEMU
%In this chapter we are going to describe the format of the input data, that
%our system require for training and present all the available datasets.
%The differences between the suggested data can seem minor but they can
%have impact on the overall performance of the system.

%To train our system, we require sentence-level aligned set of source sentences,
%MT output and a reference sentences
%TODO: footnote - reference in this thesis as a triparallel data
%. The reference sentences can be either
%a classic reference translation of the source text or a result of a human
%post-editation of the MT output, they are however required because they
%provide use with the possible corrections of the MT output.
%Naturally, the closer the MT output is
%to the reference translation, the easier it should be for our system
%to extract valuable learning instances form the sentences. We also
%considered using only pair of sentence aligned pair of MT translated
%sentences and the reference sentences however, this way the trained
%model will lose some of the useful features which can be extracted from
%the triparallel data.
%XXX

In this chapter we are going to take a closer look at the available
sources of data and describe how they contributed to our research.

We came across a various sources of training data with various level
of usefulness. Data was usually available only in a smaller volume. Some of the sources
are:
\begin{itemize}
\item Khan's school human
post-edits of manually translated (EN$\rightarrow$CS) subtitles,
\item the Autodesk
triparallel data\footurl{https://autodesk.app.box.com/Autodesk-PostEditing},
\item log files of human post-editing done by Lingea for the
HimL\footurl{http://www.himl.eu/} project test dataset,

% uvest QT21?
%\item data from the QT21 project\footurl{http://www.qt21.eu/deliverables/annotations/},

%TODO: wmt - odkaz, footnote?
\item results from the previous workshops on machine translation (namely WMT10 dataset \citep{callisonburch-EtAl:2010:WMT},
and the datasets available for the upcoming WTM16).
\end{itemize}

In the following sections, we will describe each in more detail.

\subsection{Khan's school}

The data provided by Khan's school consist of English-Czech subtitles,
where the Czech part (usually manually translated from English) was manually
edited. During the analysis of the dataset,
we've noticed that most of the time, the corrections were made
mostly on a lexical level which is only natural since the Czech sentences
were created by a human translator.
Therefore we have concluded that this dataset has little to no value
for the task of training model for correcting errors in morphology.

%Therefore, we decided to avoid using this dataset for the time being or to
%rather treat the corpus as a simple bilingual data.

\subsection{Autodesk}

Autodesk data consist of English sentences which were machine translated into
a set of target languages (cs, de, pl etc.) complemented with human post-editing
of the MT output. However, these datasets are domain specific (mostly user documentations),
so they might not be very attractive to use with more general texts.
We weren't able to gather any information about the MT system that was used
to create the translated output. The biggest advantage of these data is
their larger volume when compared with other post-editing datasets so we
used them mainly for model developement and benchmarking of the used machine
learning methods.

\subsection{HimL-Lingea logs}

The data provided by Lingea\footurl{http://www.lingea.cz/} were collected when official test sets for
Healt In My Language\footurl{http://www.himl.eu/} (HimL) project were
created. The data consist mainly of the public health related texts.
The original English sentences were first
machine-translated to languages at which
the project was aimed (Czech, German, Polish and Romanian)
and then post-edited by professional
translators using Lingea's post-editing tool. The datasets are probably the most
detailed one since they consist of complete logfiles
describing elementary actions taken by human post-editors (such as selecting
phrases in a translated sentence, looking up alternative translations
in a dictonary etc.).

When we examined the data more closely,
we noticed that it is rather difficult to determine which actions are
useful for our machine learning process. Also, we were little disapointed
when we found out that most of the time, the post-editors preferred to
rewrite the whole sentence "from scratch"\footnote{By that, we mean that the
human post-editor usually preffered to rewrite the whole corrected sentence, even though
only a several changes (either lexical and morphological) were made, and delete the original.
This might have been also motivated by the need of reordering of the MT output.}
opposite to doing more atomic modifications to the provided MT output.

In the end, we decided to simply extract a triparallel data from these logs (the source
sentence + SMT output + result of the human post-editing). In the future,
we might consider to use other logged actions for model training.

\subsection{WMT datasets}

For the last decade, the workshop on machine translation (WMT) has aimed
to provide working grounds for many researchers in the field of machine
translation. It has been great source of the parallel data between English
on one side and various other languages on the other. Each year, the scope
of the workshop expands, including various new subtask related to machine translation,
such as several evaluation tasks and, more recently, automatic post-editing task.

The data available for the post-editing task usually contains a set of:
\begin{itemize}
    \item source English sentences,
    \item output of various MT systems, usually the ones that participate in the main
translation tasks,
    \item either a reference sentences or human post-editing of the MT output from the participating MT systems.
\end{itemize}

These datasets give us the opportunity to compare the performace of our post-editing
models when applied to the different systems. Even though the data available for the
WMT subtasks are often from various domains (news, IT, biomedical), the domain of the post-editing
data is more limited, mainly to the news articles.

\subsection{Other sources}

The sources listed above (each one to a different degree) can
be considered a knowledge base for examining the behaviour of a human post-editors as well
as training data for our system. We think that they provided us with
some interesting insight into the post-editor's thought process. On the other hand,
we have also considered using other sources since the data mentioned above are quite
limited.

One possible way to face the data sparsity is to use available parallel corpora.
These corpora (containing only \notion{source sentences + reference translations})
can be expanded by translating the source sentences and thus creating a set of 
sentences which contain MT generated errors and should be fixed to resemble the 
reference translation. These data can be then used to train post-editing models for that
specific SMT system\footnote{Obviously, the post-editing model training data have to be
different from the parallel data used for the training of the SMT system, so
some
jackknife sampling should be used with limited training data.} or possibly for
other SMT systems.
This method can surely help to overcome the aforementioned data acquisition bottleneck
since there is generally much more parallel data then post-edited sentences. For
English-Czech language pair, the natural choice of the parallel corpus would be
CzEng~1.0 \citep{czeng10:lrec2012}\footurl{http://ufal.mff.cuni.cz/czeng}.

%We didn't use this approach in the scope of this thesis however, it might
%be considered in our future work.
%\todo{posledni vetu az do shrnuti?}

Of course, this aproach introduces some additional noise
related to the post-editing task. For example, we can get fluent MT output which
is just a variation on the reference translation (possibly thanks to the different
choice of wording etc.). It can be therefore hard to distinguish these fairly correct training
instances from the incorrect ones.

The basic summary of the available data is shown in the table \Tref{avail-data}.

\subsection{Monolingual data}

We have also considered simply using bitext monolingual data (either \notion{MT output + post-edited sentences}
or \notion{MT output + reference translations}), however due to the nature of our processing
pipeline we would be much more limited when analyzing the training data. Also this way, we would
lose the additional information that can be extracted from the source sentences, which proved to be valuable in the practice.
\todo{citovat priklady?}

\begin{table*}[t]
\centering
\small

\begin{tabular}{lcccc}
\multirow{2}{*}{}  &  \multirow{2}{*}{\hash{} Sentences}  &  \multicolumn{3}{c}{\hash{} Tokens}  \\
&   & English & Czech (MT) & Czech (PE) \\
\hline
Khan's school & \tilda{}14k & \tilda{}93k & \tilda{}93k & \tilda{}93k \\
Autodesk & 46,916 & 490,005 & 456,697 & 441,645 \\
HimL-Lingea & 3892 & 60,142 & 51,428 & 56,485 \\
WMT10 & 2,489 & 54,021 & 44,578 & 45,422 \\
WMT16 & 2,999 & 57,418 & 48,037 & 48,915 \\
CzEng 1.0 & 15M & 206M & NA & 150M \\
\end{tabular}
\caption{Summary of the available post-editing data. Only English-Czech data is listed, however, for datasets
where data for other language pairs are available, their volume is roughly the same. We provide only rough estimates for the Khan's school data.
There is no information about the number of tokens in the MT part of CzEng because we have decide to abandon the
idea of creating a triparallel corpora for the time being.
}
\label{avail-data}
\end{table*}

%The
%number of parallel sentences and the number of tokens in the English source, the
%MT output (\equo{MT}) and the post-edited MT output (\equo{PE}). Only
%English-Czech data is listed since these datasets for other target languages
%(where available) are similar in volume.
%For Khan's school, we only
%provide estimates. The CzEng data set is not translated by any SMT at the moment,
%so the related information is omitted. We provide the information only for comparison.

%We do not include information about the QT21 data since we are yet to explore them.

